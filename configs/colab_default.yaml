action: ???
name: ???
modality: ???
total_batch: 32 
batch_size: 32 
gpus: null 
wandb_name: null 
resume_from: null 
logname: null 
models_dir: null 

train:
  num_iter: 200 
  lr_steps: 190 
  eval_freq: 10 
  
test:
  
dataset:
  name: ???
  annotations_path: ???
  workers: 4 # number of workers for the dataloader
  resolution: 224 # input resolution to the model
  RGB:
    data_path:  ../Datasets/
    tmpl: "img_{}_{:010d}_{}_{}_{}.png" # format of RGB filenames. CAld3r&Mend3s example: "F_001_1120_anger_Color"
  DEPTH:
    data_path: ../Datasets/
    tmpl: "img_{}_{:010d}_{}_{}_{}.png"
  MESH:
  data_path: ../Datasets/
  tmpl: "img_{}_{:010d}_{}_{}_{}.png"

# these are the action recognition models for each modality
models:
  RGB:
    model: ???
    normalize: False
    dropout: 0.4
    kwargs: {}
    lr_steps: 3000
    lr: 0.01
    sgd_momentum: 0.9
    weight_decay: 1e-7
  DEPTH:
    model: ???
    normalize: False
    dropout: 0.5
    kwargs: {}
    lr_steps: 3000
    lr: 0.01
    sgd_momentum: 0.9
    weight_decay: 1e-7
  MESH:
    model: ???
    normalize: False
    dropout: 0.5
    kwargs: {}
    lr_steps: 3000
    lr: 0.01
    sgd_momentum: 0.9
    weight_decay: 1e-7
  VOXEL: 
  model: ???
  normalize: False
  dropout: 0.5
  kwargs: {}
  lr_steps: 3000
  lr: 0.01
  sgd_momentum: 0.9
  weight_decay: 1e-7
